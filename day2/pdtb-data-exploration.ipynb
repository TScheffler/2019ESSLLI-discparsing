{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to work with the PDTB\n",
    "\n",
    "_based on the course \"Computational Pragmatics\" by Chris Potts_ \n",
    "\n",
    "Shared under a cc-by-nc-sa license.\n",
    "https://creativecommons.org/licenses/by-nc-sa/3.0/\n",
    "\n",
    "## Loading & accessing the corpus\n",
    "\n",
    "We can access the corpus using the compiled csv-version (a tabular format with one relation per line): https://bit.ly/2TjfT5K (you should know the password). \n",
    "\n",
    "The python package `pdtb` provides an iterator over the data points in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs NLTK\n",
    "\n",
    "from collections import defaultdict\n",
    "from pdtb import CorpusReader, Datum\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "pdtb = CorpusReader('pdtb2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_count():\n",
    "    \"\"\"Calculate and display the distribution of relations.\"\"\"\n",
    "    # Create a count dictionary of relations.\n",
    "    d = defaultdict(int)\n",
    "    for datum in pdtb.iter_data():\n",
    "        if datum.Relation == None:\n",
    "            break\n",
    "        d[datum.Relation] += 1\n",
    "    # Print the results to standard output.\n",
    "    for key, val in d.items():\n",
    "        print(key, val)\n",
    "    return()\n",
    "\n",
    "# This will take a long time, so run with caution!\n",
    "relation_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the corpus\n",
    "\n",
    "* Example relation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datum in pdtb.iter_data():\n",
    "#     print(datum)\n",
    "#     break\n",
    "    \n",
    "print(next(pdtb.iter_data()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What information do we have for each relation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datum.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_item = next(x for i,x in enumerate(pdtb.iter_data()) if i==3) # Get the 3rd relation\n",
    "print(ex_item.Relation,ex_item.ConnHead,ex_item.FullRawText)\n",
    "\n",
    "print(\"Arg1 = \" + ex_item.Arg1_RawText)\n",
    "print(\"Arg2 = \" + ex_item.Arg2_RawText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic classes\n",
    "\n",
    "We can look at the semantic classes present in the corpus.\n",
    "\n",
    "*NOTE:* This is the 2.0 version of the PDTB, which still uses the (deprecated) PDTB 2.0 set of relations. PDTB 3.0 has just been released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_semantic_classes():\n",
    "    \"\"\"Count ConnHeadSemClass1 values.\"\"\"\n",
    "    d = defaultdict(int)\n",
    "    for datum in pdtb.iter_data():\n",
    "        sc = datum.ConnHeadSemClass1\n",
    "        # Filter None values (should be just EntRel/NonRel data).\n",
    "        if sc:\n",
    "            d[sc] += 1\n",
    "    return d\n",
    "\n",
    "sem = count_semantic_classes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (18, 5)\n",
    "\n",
    "plt.bar(*zip(*sem.items()))\n",
    "xticks(rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connectives\n",
    "\n",
    "Looking at the connectives (only for *Explicit* relations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_connectives():\n",
    "    \"\"\"Print all connectives.\"\"\"\n",
    "    d = defaultdict(int)\n",
    "    for datum in pdtb.iter_data():\n",
    "        if datum.Relation == \"Explicit\":\n",
    "            conn = datum.ConnHead\n",
    "            d[conn] += 1\n",
    "    return d\n",
    "\n",
    "ALL_CONNECTIVES = print_connectives()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(*zip(*ALL_CONNECTIVES.items()))\n",
    "xticks(rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering some questions about the data\n",
    "\n",
    "### Disconnected argument spans\n",
    "\n",
    "When does it happen that argument spans are not continuous (that is, something is \"missing\" from within either argument)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for datum in pdtb.iter_data():\n",
    "    i+=1\n",
    "    if i>200:\n",
    "        break\n",
    "    if datum.Relation==\"Explicit\":\n",
    "        arg1spans = datum.Arg1_SpanList\n",
    "        arg2spans = datum.Arg2_SpanList\n",
    "        if len(arg1spans)+len(arg2spans)>2:\n",
    "            print(datum.ConnHead, datum.Connective_SpanList,arg1spans,arg2spans)\n",
    "            print(datum)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at syntactic trees\n",
    "\n",
    "Potts has also included the syntactic trees of arguments (and connectives) in the same data structure. This means we can look at them and for example see which types of arguments occur for certain connectives, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for datum in pdtb.iter_data():\n",
    "    i+=1\n",
    "    if i>200:\n",
    "        break\n",
    "    if datum.Relation==\"Implicit\":\n",
    "        print(datum)\n",
    "        print(datum.Arg1_Trees)\n",
    "        print(datum.Arg2_Trees)\n",
    "        break\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercises\n",
    "\n",
    "1. Which semantic senses occur in *Explicit* vs. *Implicit* relations? Construct a confusion matrix with the Relation types as rows, the ConnHeadSemClass1 as colums, and the cells representing the number of times that the correspondong row and columns values occur together. Are there patterns here that we might take advantage of in experiments predicting Relation-types or semantic coherence classes?\n",
    "2. Find long-distance relations. These are relations where there is some extra material in between argument 1 and 2. For this, you may want to use functionality similar to the `adjacency_check`-function below. When you find a long-distance relation, save what type of relation it is (should be mainly Explicit), and what the connective is (`ConnHead`). Further, `Datum` also provides a method called `relative_arg_order()`. The function `distribution_of_relative_arg_order()` defined below creates a simple tally of the relative argument orders (Arg1 befor Arg2, Arg2 before Arg1, etc.).\n",
    "3. How does the **size** of arguments correlate with connectives? Create a dictionary of connective heads and argument sizes. Plot the argument size distributions for a few connectives (or the means for all connectives). \n",
    "4. What is the syntactic type of arguments? Which kinds of clauses can you find?\n",
    "5. What is happening in \"Attribution\"s? Eg, use the function `def print_attribution_texts()` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjacency_check(datum):\n",
    "    \"\"\"Return True if datum is of the form Arg1 (connective) Arg2, else False\"\"\"    \n",
    "    if not datum.arg1_precedes_arg2():\n",
    "        return False\n",
    "    arg1_finish = max([x for span in datum.Arg1_SpanList for x in span])\n",
    "    arg2_start = min([x for span in datum.Arg2_SpanList for x in span])    \n",
    "    if datum.Relation == 'Implicit':\n",
    "        if (arg2_start - arg1_finish) <= 3:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        conn_indices = [x for span in datum.Connective_SpanList for x in span]\n",
    "        conn_start = min(conn_indices)\n",
    "        conn_finish = max(conn_indices)\n",
    "        if (conn_start - arg1_finish) <= 3 and (arg2_start - conn_finish) <= 3:\n",
    "            return True\n",
    "        else:\n",
    "            return False        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_check(ex_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def distribution_of_relative_arg_order():\n",
    "    d = defaultdict(int)\n",
    "    pdtb = CorpusReader('pdtb2.csv')\n",
    "    for datum in pdtb.iter_data(display_progress=True):\n",
    "        d[datum.relative_arg_order()] += 1\n",
    "    for order, count in sorted(list(d.items()), key=itemgetter(1), reverse=True):\n",
    "        print(order, count)\n",
    "    \n",
    "distribution_of_relative_arg_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_attribution_texts():\n",
    "    \"\"\"Inspect the strings characterizing attribution values.\"\"\"\n",
    "    pdtb = CorpusReader('pdtb2.csv')\n",
    "    for datum in pdtb.iter_data(display_progress=False):\n",
    "        txt = datum.Attribution_RawText\n",
    "        if txt:\n",
    "            print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = print_attribution_texts()\n",
    "attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
